{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'M':1,'B':0}\n",
    "dataset = dataset.replace(d)\n",
    "dataset = dataset.drop(['Unnamed: 32'],axis=1) \n",
    "dataset = dataset.drop(['id'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp = dataset.drop(['diagnosis'],axis=1)\n",
    "X = np.array(dataset_temp).T\n",
    "Y = np.array(dataset['diagnosis']).T \n",
    "Y = Y.reshape(1,569)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = np.mean(X,axis=1,keepdims=True) #Find the mean of each feature\n",
    "X_max = np.max(X,axis=1,keepdims=True) #Find the maximum of each feature\n",
    "X_normalized = (X-X_mean)/(X_max) #Normalizing our dataset by subtracting the mean and dividing by the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_normalized[:,:380]\n",
    "Y_train = Y[:,:380]\n",
    "\n",
    "X_cv = X_normalized[:,381:]\n",
    "Y_cv = Y[:,381:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    s = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X,W1,W2,W3,b1,b2,b3):\n",
    "    \n",
    "    #First layer forward propogation\n",
    "    Z1 = np.dot(W1,X)\n",
    "    A1 = tanh(Z1 + b1)\n",
    "    #Second layer forward propogation\n",
    "    Z2 = np.dot(W2,A1)\n",
    "    A2 = tanh(Z2 + b2)\n",
    "    #Third layer forward propogation\n",
    "    Z3 = np.dot(W3,A2)\n",
    "    A3 = sigmoid(Z3 + b3) #A3 will produce our probability vector\n",
    "    \n",
    "    cache = {    \n",
    "                  \"Z1\": Z1,\n",
    "                  \"A1\": A1,\n",
    "                  \"Z2\": Z2,\n",
    "                  \"A2\": A2,\n",
    "                  \"Z3\": Z3,\n",
    "                  \"A3\": A3\n",
    "            }\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient_descent(iterations,X,Y,alpha):\n",
    "    \n",
    "    #Randomly initialized our parameters before running the algorithm\n",
    "    W1 = np.random.randn(3,30)*0.01\n",
    "    b1 = np.random.rand(3,1)\n",
    "    W2 = np.random.randn(2,3)*0.01\n",
    "    b2 = np.random.rand(2,1)\n",
    "    W3 = np.random.rand(1,2)*0.01\n",
    "    b3 = np.random.rand(1,1)\n",
    "    dummy,m = X.shape\n",
    "    \n",
    "    caches = [] \n",
    "    count_vector = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range (1,iterations):\n",
    "        \n",
    "            count = count + 1\n",
    "            \n",
    "            count_vector.append(count)\n",
    "        \n",
    "            params = forward_prop(X,W1,W2,W3,b1,b2,b3)\n",
    "            \n",
    "            Z1 = params['Z1']\n",
    "            Z2 = params['Z2']\n",
    "            Z3 = params['Z3']\n",
    "            A1 = params['A1']\n",
    "            A2 = params['A2']\n",
    "            A3 = params['A3']\n",
    "            \n",
    "            #Define our cost function, append the cost of each iteration to caches\n",
    "            cost = -(1 / m)*np.sum(np.multiply(Y,np.log(A3)) + np.multiply((1-Y),np.log(1-A3)))\n",
    "            caches.append(cost)\n",
    "            \n",
    "            #Back propogation for layer 3\n",
    "            dA3 = -Y/A3 + (1-Y)/(1-A3)\n",
    "            dZ3 = dA3 * sigmoid(Z3)*(1-sigmoid(Z3))\n",
    "            dW3 = (1 / m)*np.dot(dZ3,A2.T)\n",
    "            db3 = (1 / m)*np.sum(dZ3,axis=1,keepdims=True)\n",
    "            \n",
    "            #Back propogation for layer 2\n",
    "            dA2 = np.dot(W3.T,dZ3)\n",
    "            dZ2 = dA2*(1-np.power(tanh(Z2),2))\n",
    "            dW2 = (1 / m)*np.dot(dZ2,A1.T)\n",
    "            db2 = (1 / m)*np.sum(dZ2,axis=1,keepdims=True)\n",
    "            \n",
    "            #Back propogation for layer 1\n",
    "            dA1 = np.dot(W2.T,dZ2)\n",
    "            dZ1 = dA1*(1-np.power(tanh(Z1),2))\n",
    "            dW1 = (1 / m)*np.dot(dZ1,X.T)\n",
    "            db1 = (1 / m)*np.sum(dZ1,axis=1,keepdims=True)\n",
    "            \n",
    "            #Redefine our weight parameters using the derivatives calculated in back propogation\n",
    "            W1 = W1 - alpha*dW1\n",
    "            W2 = W2 - alpha*dW2\n",
    "            W3 = W3 - alpha*dW3\n",
    "            \n",
    "            #Redefine our weight parameters using the derivatives calculated in back propogation\n",
    "            b1 = b1 - alpha*db1\n",
    "            b2 = b2 - alpha*db2\n",
    "            b3 = b3 - alpha*db3\n",
    "        \n",
    "    return W1,W2,W3,b1,b2,b3,count_vector,caches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W1,W2,W3,b1,b2,b3,count,caches = gradient_descent(1000,X_cv,Y_cv,0.5)\n",
    "\n",
    "plt.plot(count,caches,label='Cost')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "plt.title(\"Cost vs. Iteration\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,Y,iterations,alpha,X_train,Y_train):\n",
    "\n",
    "    W1,W2,W3,b1,b2,b3,count,caches = gradient_descent(iterations,X_train,Y_train,alpha)\n",
    "    \n",
    "    Z1 = np.dot(W1,X)\n",
    "    A1 = tanh(Z1 + b1)\n",
    "    Z2 = np.dot(W2,A1)\n",
    "    A2 = tanh(Z2 + b2)\n",
    "    Z3 = np.dot(W3,A2)\n",
    "    A3 = sigmoid(Z3 + b3)\n",
    "    \n",
    "    dummy,m = A3.shape\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        Y_prediction[0, i] = 1 if A3[0, i] > 0.5 else 0\n",
    "        \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 98.6842105263158 %\n",
      "Cross validation accuracy: 96.80851063829788 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(predict(X_train,Y_train,1000,0.5,X_train,Y_train) - Y_train)) * 100))\n",
    "print(\"Cross validation accuracy: {} %\".format(100 - np.mean(np.abs(predict(X_cv,Y_cv,1000,0.5,X_train,Y_train) - Y_cv)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 positives predicted on the training set\n",
      "168 true positives are in the training set\n",
      "The accuracy of true positives on the training set is: 97.61904761904762 %\n",
      "----------------------------------------------------------------\n",
      "43 positives predicted on the cross validation set\n",
      "43 true positives are in the cross validation set\n",
      "The accuracy of true positives on the cross validation set is: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "dummy,m1 = X_train.shape\n",
    "dummy,m2 = X_cv.shape\n",
    "\n",
    "train_predict = predict(X_train,Y_train,1000,0.5,X_train,Y_train)\n",
    "CV_predict = predict(X_cv,Y_cv,1000,0.5,X_train,Y_train)\n",
    "count_true_pos = 0\n",
    "count_train_pos = 0\n",
    "\n",
    "count_true_pos_cv = 0\n",
    "count_cv_pos = 0\n",
    "\n",
    "for i in range (1,m1):\n",
    "    if train_predict[0,i] == 1 and Y_train[0,i] == 1:\n",
    "        count_true_pos = count_true_pos + 1\n",
    "    if Y_train[0,i] == 1:\n",
    "        count_train_pos = count_train_pos + 1\n",
    "        \n",
    "for i in range (1,m2):\n",
    "    if CV_predict[0,i] == 1 and Y_cv[0,i] == 1:\n",
    "        count_true_pos_cv = count_true_pos_cv + 1\n",
    "    if Y_cv[0,i] == 1:\n",
    "        count_cv_pos = count_cv_pos + 1\n",
    "        \n",
    "print(str(count_true_pos) + \" positives predicted on the training set\")\n",
    "print(str(count_train_pos) + \" true positives are in the training set\")\n",
    "print(\"The accuracy of true positives on the training set is: {} %\".format(100-np.abs(100*((count_true_pos - count_train_pos)/count_train_pos))))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(str(count_true_pos_cv) + \" positives predicted on the cross validation set\")\n",
    "print(str(count_cv_pos) + \" true positives are in the cross validation set\")\n",
    "print(\"The accuracy of true positives on the cross validation set is: {} %\".format(100-np.abs(100*((count_true_pos_cv - count_cv_pos)/count_true_pos_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 negatives predicted on the training set\n",
      "211 true negatives are in the training set\n",
      "The accuracy of true negatives on the training set is: 99.0521327014218 %\n",
      "----------------------------------------------------------------\n",
      "138 negatives predicted on the cross validation set\n",
      "144 true negatives are in the cross validation set\n",
      "The accuracy of true negatives on the cross validation set is: 95.65217391304348 %\n"
     ]
    }
   ],
   "source": [
    "count_true_neg = 0\n",
    "count_train_neg = 0\n",
    "\n",
    "count_true_neg_cv = 0\n",
    "count_cv_neg = 0\n",
    "\n",
    "for i in range (1,m1):\n",
    "    if train_predict[0,i] == 0 and Y_train[0,i] == 0:\n",
    "        count_true_neg = count_true_neg + 1\n",
    "    if Y_train[0,i] == 0:\n",
    "        count_train_neg = count_train_neg + 1\n",
    "        \n",
    "for i in range (1,m2):\n",
    "    if CV_predict[0,i] == 0 and Y_cv[0,i] == 0:\n",
    "        count_true_neg_cv = count_true_neg_cv + 1\n",
    "    if Y_cv[0,i] == 0:\n",
    "        count_cv_neg = count_cv_neg + 1\n",
    "        \n",
    "print(str(count_true_neg) + \" negatives predicted on the training set\")\n",
    "print(str(count_train_neg) + \" true negatives are in the training set\")\n",
    "print(\"The accuracy of true negatives on the training set is: {} %\".format(100-np.abs(100*((count_true_neg - count_train_neg)/count_train_neg))))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(str(count_true_neg_cv) + \" negatives predicted on the cross validation set\")\n",
    "print(str(count_cv_neg) + \" true negatives are in the cross validation set\")\n",
    "print(\"The accuracy of true negatives on the cross validation set is: {} %\".format(100-np.abs(100*((count_true_neg_cv - count_cv_neg)/count_true_neg_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
